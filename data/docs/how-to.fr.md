# Comment utiliser l'application

Vous Ãªtes enseignant, Ã©tudiant ou juste un curieux de passage ?

Bienvenue ! Dans ce bref aperÃ§u, vous dÃ©couvrirez ce que cette application peut faire et comment en tirer le meilleur parti.

## Ã€ quoi sert l'application ?

**CommenÃ§ons par ce que AnimatedLLM n'est pas.**

AnimatedLLM n'est pas (du moins pour l'instant !) une application Ã©ducative complÃ¨te qui vous guidera Ã  travers le fonctionnement des grands modÃ¨les de langage de A Ã  Z.

Pour bien comprendre le sujet, vous devrez Ã©galement consulter d'autres ressources.

Pour commencer, essayez cette courte vidÃ©o de la chaÃ®ne [3Blue1Brown](https://www.youtube.com/@3blue1brown/videos) (en anglais, avec des sous-titres dans de nombreuses langues) :

<iframe width="560" height="315" src="https://www.youtube.com/embed/LPZh9BOjkQs?si=Nogb8BgfP9kL1DIa" title="YouTube video player" frameborder="0" allow="clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

Vous trouverez de nombreux autres supports sur Internet. Parmi les ressources de qualitÃ©, citons ces articles de blog illustrÃ©s de Jay Alammar :

- **[Illustrated GPT-2](https://jalammar.github.io/illustrated-gpt2/)**
- **[Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/)**

Pour les Ã©tudiants tchÃ¨ques, il existe des cours universitaires directement axÃ©s sur les grands modÃ¨les de langage :

- **MFF UK :** [Large Language Models (NPFL140)](https://ufal.mff.cuni.cz/courses/npfl140)
- **FIT ÄŒVUT :** [Neural Language Models (NI-NLM)](https://bilakniha.cvut.cz/en/predmet8241006.html)
 
 
(Note : l'auteur de l'application participe au premier cours et dirige le second ğŸ˜‡)

**Alors, Ã  quoi sert AnimatedLLM ?**

Les animations d'AnimatedLLM servent principalement d'outil pÃ©dagogique. Elles aident Ã  expliquer les principes de fonctionnement des modÃ¨les de langage qui, autrement, nÃ©cessiteraient de longues explications gestuelles ou des schÃ©mas au tableau.

Par exemple :
- D'oÃ¹ vient le texte gÃ©nÃ©rÃ© par le modÃ¨le ?
- Que signifie le fait qu'un modÃ¨le soit Â« entraÃ®nÃ© sur des documents Â» ?
- D'oÃ¹ proviennent exactement les probabilitÃ©s du prochain token ?
- etc.


Cependant, comprendre pourquoi nous abordons ces processus, comment les modÃ¨les de langage sont nÃ©s et quel est leur rÃ´le dans des services complexes comme ChatGPT, Gemini ou Claude, est un sujet qu'il faudra Ã©tudier ailleurs.


**Dernier avertissement...**

Certains principes des modÃ¨les de langage sont simplifiÃ©s dans AnimatedLLM. Pas de maniÃ¨re excessive, mais certains dÃ©tails techniques sont omis par souci de clartÃ©.

Si ces dÃ©tails techniques vous intÃ©ressent, les animations suivantes approfondissent davantage l'architecture des modÃ¨les :
- [llm-viz](https://bbycroft.net/llm)
- [Transformer Explainer](https://poloclub.github.io/transformer-explainer/)

## Comment l'application fonctionne-t-elle ?

Les animations de AnimatedLLM sont des **interactions enregistrÃ©es avec de rÃ©els modÃ¨les de langage**.

Cela signifie deux choses :
- Les animations montrent le comportement rÃ©aliste de vÃ©ritables modÃ¨les de langage.
- Aucun modÃ¨le de langage ne tourne rÃ©ellement pendant les animations ; il s'agit simplement d'un enregistrement lu dans le navigateur.

### Comment les enregistrements ont-ils Ã©tÃ© crÃ©Ã©s ?
Les enregistrements ont Ã©tÃ© gÃ©nÃ©rÃ©s Ã  partir de modÃ¨les de langage open-source plus petits provenant du dÃ©pÃ´t [Hugging Face](https://huggingface.co/models).

Les modÃ¨les ont tournÃ© sur un cluster de calcul universitaire via le framework [vLLM](https://github.com/vllm-project/vllm). Ce framework permet de collecter des dÃ©tails prÃ©cis, tels que les probabilitÃ©s des prochains tokens.

Les prompts et les documents ont Ã©tÃ© choisis pour dÃ©montrer divers phÃ©nomÃ¨nes intÃ©ressants (par exemple, Â« pourquoi les modÃ¨les ne savent-ils pas bien compter les lettres ? Â»).

Les donnÃ©es sont disponibles pour diffÃ©rents :
- modÃ¨les,
- tempÃ©ratures de dÃ©codage,
- langues.

Vous trouverez les scripts pour gÃ©nÃ©rer les enregistrements dans le [dÃ©pÃ´t du projet](https://github.com/kasnerz/animated-llm/tree/main/scripts/data-generation).

Vous y trouverez Ã©galement un script permettant de [tÃ©lÃ©charger et explorer](https://github.com/kasnerz/animated-llm/blob/main/scripts/download_data.py) tous les enregistrements actuels au format JSON.

### Quelles donnÃ©es sont prÃ©sentes dans les enregistrements ?

âš  Attention, ces informations ont pu partiellement changer depuis.

#### ModÃ¨le
L'application comprend les sorties des modÃ¨les suivants :
- [CohereForAI/aya-expanse-8b](https://huggingface.co/CohereForAI/aya-expanse-8b)
- [meta-llama/Llama-3.2-1B-Instruct](https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct)
- [Qwen/Qwen3-4B-Instruct-2507](https://huggingface.co/Qwen/Qwen3-4B-Instruct-2507)
- [allenai/Olmo-3-7B-Think](https://huggingface.co/allenai/Olmo-3-7B-Think)
- [openai-community/gpt2-xl](https://huggingface.co/openai-community/gpt2-xl)

Pour l'entraÃ®nement, un enregistrement d'un Â« Transformer vanilla Â» est Ã©galement disponible, c'est-Ã -dire un modÃ¨le avec des poids initialisÃ©s alÃ©atoirement (il est basÃ© sur l'architecture `Llama-3.2-1B-Instruct`, mais ce n'est qu'un dÃ©tail technique).

#### TempÃ©rature de dÃ©codage
La tempÃ©rature de dÃ©codage est un nombre compris entre 0 et âˆ qui dÃ©termine (pour simplifier) le degrÃ© de hasard dans la sÃ©lection des prochains tokens.

Alors qu'Ã  une tempÃ©rature proche de zÃ©ro, le token le plus probable est presque toujours choisi, Ã  une tempÃ©rature trÃ¨s Ã©levÃ©e, les prÃ©dictions du modÃ¨le ne sont pratiquement plus prises en compte et le token est choisi de maniÃ¨re alÃ©atoire.

Dans l'application, les enregistrements sont disponibles pour les valeurs de tempÃ©rature suivantes :
- ğŸ§Š **0.0** : le token le plus probable est toujours sÃ©lectionnÃ©,
- ğŸŒ¡ **1.0** : le token est sÃ©lectionnÃ© alÃ©atoirement sur la base des probabilitÃ©s du modÃ¨le,
- ğŸ”¥ **5.0** : le token est sÃ©lectionnÃ© alÃ©atoirement et les probabilitÃ©s du modÃ¨le ne jouent qu'un rÃ´le mineur.

#### Langue

Nous fournissons les enregistrements dans toutes les langues supportÃ©es par l'application. Celles-ci sont actuellement :

- ğŸ‡¬ğŸ‡§ Anglais
- ğŸ‡¨ğŸ‡¿ TchÃ¨que
- ğŸ‡«ğŸ‡· FranÃ§ais
- ğŸ‡ºğŸ‡¦ Ukrainien
- ğŸ‡¨ğŸ‡³ Chinois

Les langues ont Ã©tÃ© choisies pour couvrir un large Ã©ventail de familles de langues et d'Ã©critures.

Vous souhaitez ajouter d'autres langues ou corriger des erreurs ? Rendez-vous dans la section Â« Comment donner mon avis sur l'application ? Â»

âš  Attention : Ã  l'exception de l'anglais et du tchÃ¨que, la traduction du site a Ã©tÃ© crÃ©Ã©e automatiquement Ã  l'aide de grands modÃ¨les de langage.


## Comment contrÃ´ler l'application ?
### Comment choisir un enregistrement spÃ©cifique ?

1. Choisissez sur l'Ã©cran d'accueil l'aspect des modÃ¨les de langage qui vous intÃ©resse.
2. SÃ©lectionnez le **modÃ¨le et la tempÃ©rature** dans les paramÃ¨tres. Dans certaines animations, ce rÃ©glage est visible directement, ailleurs il est cachÃ© sous l'icÃ´ne :

![settings](img/settings.png)

3. Choisissez la **langue** via l'icÃ´ne du drapeau. (Actuellement, le changement de langue de l'enregistrement est liÃ© au changement de langue de toute l'application) :

![language](img/languages.png)

4. Lancez l'animation en cliquant sur le bouton Â« Play Â».

### Astuce pour les experts

L'animation peut Ã©galement Ãªtre contrÃ´lÃ©e Ã  l'aide de raccourcis clavier.

Au lieu du bouton Â« Play Â», vous pouvez par exemple faire dÃ©filer l'animation Ã©tape par Ã©tape avec la flÃ¨che droite, ou revenir en arriÃ¨re avec la flÃ¨che gauche.

Et il y a bien d'autres raccourcis !

Vous trouverez tous les raccourcis sous l'icÃ´ne du clavier :

![keyboard](img/keyboard.png)


## Comment donner mon avis sur l'application ?

Veuillez envoyer vos questions et idÃ©es d'amÃ©lioration sur le **[forum de discussion GitHub](https://github.com/kasnerz/animated-llm/discussions)**.

Si vous n'avez pas de compte GitHub, vous pouvez Ã©galement Ã©crire directement Ã  l'auteur principal de l'application ([ZdenÄ›k Kasner](https://kasnerz.github.io), vous trouverez son e-mail par exemple [ici](https://ufal.mff.cuni.cz/zdenek-kasner)).